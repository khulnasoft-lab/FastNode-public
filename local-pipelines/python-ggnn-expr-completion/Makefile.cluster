MODEL_NAME := type_subtokens
DATASET_NAME ?= $(MODEL_NAME)
RUNDB :=

TENSORBOARD_DIR := ./tensorboard
OUT_DIR := ./out
OUT_SERVE_DIR := ./out/serve
TMP_DIR := ./tmp
SAMPLES_DIR ?= /data/samples
DATA_DIR := $(SAMPLES_DIR)/$(DATASET_NAME)
CLUSTERS_FILE := clusters-$(MODEL_NAME).txt

DIRS_TO_CREATE := $(OUT_DIR) $(OUT_SERVE_DIR) $(TMP_DIR) $(TENSORBOARD_DIR) $(SAMPLES_DIR) $(DATA_DIR)

BUNDLE_NAME := bundle

TENSORBOARD_PATH := $(TENSORBOARD_DIR)/$(MODEL_NAME)
SAVED_MODEL_PATH := saved_model
COMPRESSED_FROZEN_MODEL_PATH := expr_model.frozen.pb
FROZEN_MODEL_PATH := expr_model.uncompressed.frozen.pb
ATTR_FALLBACK_PATH := attr-fallback.txt
CKPT_PATH := ckpt

META_INFO := metainfo.json
META_INFO_FINAL := metainfo-inference.json
FASTNODE_ML_PATH := /var/fastnode/bundle/khulnasoft-lab/fastnode-python/fastnode_ml/

UPLOAD_PATH := s3://fastnode-data/python-ggnn-expr-completion

PACKAGES := ./packagelist.txt
BATCH := 20
MAX_SAMPLES := 40
ATTR_PROPORTION := 15
ATTR_BASE_PROPORTION := 5
CALL_PROPORTION := 15
ARG_TYPE_PROPORTION := 15
KWARG_NAME_PROPORTION := 15
ARG_PLACEHOLDER_PROPORTION := 45
SAMPLES_PER_FILE := 500

NUM_VALIDATE_SAMPLES := 1000

ifeq ($(DRY_RUN),1)
	STEPS := 10
	CODEBOOK_MAX_EPOCHS := 10
else
	STEPS := 1250000
	CODEBOOK_MAX_EPOCHS := 1500
endif

SYNCER_PORT := :3087

$(shell mkdir -p $(DIRS_TO_CREATE))

clean:
	rm -rf $(OUT_DIR)
	rm -rf $(TMP_DIR)
	rm -rf $(TENSORBOARD_PATH)
	rm -rf $(BUNDLE_NAME)
	rm -rf $(BUNDLE_NAME).tar.gz


SERVER := http://localhost:3039
SCORES_ENDPOINT := $(SERVER)/symbol/scores

metainfo_on_cluster:
	traindata --packages=$(PACKAGES) --out=$(TMP_DIR)/$(META_INFO) --endpoint=$(SCORES_ENDPOINT)
	mv $(TMP_DIR)/$(META_INFO) $(OUT_DIR)/$(META_INFO)
	convert --in $(OUT_DIR)/$(META_INFO) --out $(TMP_DIR)/$(META_INFO_FINAL)
	mv $(TMP_DIR)/$(META_INFO_FINAL) $(OUT_SERVE_DIR)/$(META_INFO_FINAL)

datagen_on_cluster:
	python datagen/get_data.py \
		--endpoint=http://localhost:3039 \
		--out_dir=$(DATA_DIR) \
		--random_seed=`python -c "print(100 + $(INSTANCE_ID))"` \
		--samples=`python -c "import math; print(int(math.ceil(1.1 * $(STEPS) / $(INSTANCE_COUNT))))"` \
		--samples_per_file=$(SAMPLES_PER_FILE) \
		--max_samples=$(MAX_SAMPLES) \
		--batch=$(BATCH) \
		--meta_info=$(OUT_DIR)/$(META_INFO) \
		--attr_proportion=$(ATTR_PROPORTION) \
		--attr_base_proportion=$(ATTR_BASE_PROPORTION) \
		--call_proportion=$(CALL_PROPORTION) \
		--arg_type_proportion=$(ARG_TYPE_PROPORTION) \
		--kwarg_name_proportion=$(KWARG_NAME_PROPORTION) \
		--arg_placeholder_proportion=$(ARG_PLACEHOLDER_PROPORTION)

train_on_cluster:
	python train/train.py \
		--use_synced_data=1 \
		--syncer_endpoint=http://localhost$(SYNCER_PORT) \
		--in_dir=$(DATA_DIR) \
		--meta_info=$(OUT_DIR)/$(META_INFO) \
		--out_dir=$(TMP_DIR)/$(SAVED_MODEL_PATH) \
		--frozen_model=$(TMP_DIR)/$(FROZEN_MODEL_PATH) \
		--checkpoint_path=$(TMP_DIR)/$(CKPT_PATH) \
		--tensorboard=$(TENSORBOARD_PATH) \
		--steps=$(STEPS) \
		--batch=$(BATCH)
	mv $(TMP_DIR)/$(SAVED_MODEL_PATH) $(OUT_DIR)
	mv $(TMP_DIR)/$(FROZEN_MODEL_PATH) $(OUT_DIR)/$(FROZEN_MODEL_PATH)
	cp -rv $(TENSORBOARD_DIR) $(OUT_DIR)
	python codebook/compress_embeddings.py \
    		--meta_info=$(OUT_DIR)/$(META_INFO) \
    		--in_saved_model=$(OUT_DIR)/$(SAVED_MODEL_PATH) \
    		--out_frozen_model=$(TMP_DIR)/$(COMPRESSED_FROZEN_MODEL_PATH) \
    		--models_path=$(TMP_DIR)/codebook_models \
			--max_epochs=$(CODEBOOK_MAX_EPOCHS) \
    		--train=1
	mv $(TMP_DIR)/$(COMPRESSED_FROZEN_MODEL_PATH) $(OUT_SERVE_DIR)/$(COMPRESSED_FROZEN_MODEL_PATH)

sync_on_cluster:
	rm -rf $(DATA_DIR)
	mkdir -p $(DATA_DIR)
	sync-data --remotedir=$(DATA_DIR) \
		 --localdir=$(DATA_DIR) \
		 --port $(SYNCER_PORT) \
		 --hosts $(DATAGEN_HOSTS)

validate_attribute: $(OUT_SERVE_DIR)/$(ATTR_FALLBACK_PATH)

$(OUT_SERVE_DIR)/$(ATTR_FALLBACK_PATH): $(OUT_SERVE_DIR)/$(COMPRESSED_FROZEN_MODEL_PATH) $(OUT_SERVE_DIR)/$(META_INFO_FINAL)
	@echo "===== validating attribute completions..."
	ggnn-attribute-completions \
		--fallbackpath $(TMP_DIR)/attr-fallback-pipeline.txt \
		--exprmodel $(OUT_SERVE_DIR) \
		--runname validate_attributes \
		--maxevents $(NUM_VALIDATE_SAMPLES) \
		--rundbpath $(RUNDB)
	cat $(TMP_DIR)/attr-fallback-pipeline.txt ./attr-fallback-hardcoded.txt | sort | uniq > $(TMP_DIR)/$(ATTR_FALLBACK_PATH)
	mv $(TMP_DIR)/$(ATTR_FALLBACK_PATH) $(OUT_SERVE_DIR)

validate_calls: $(OUT_SERVE_DIR)/$(ATTR_FALLBACK_PATH)
	ggnn-call-completions-validate \
		--model $(OUT_SERVE_DIR) \
		--runname validate_calls \
		--maxevents $(NUM_VALIDATE_SAMPLES) \
		--rundb $(RUNDB)
