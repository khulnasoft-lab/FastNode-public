# General

This is the pipeline that trains the general expression model (`pythonexpr`).

# Training

The `Makefile` automates the training, although the workflows are different
for training in a standalone vs distributed environment.

## Standalone

- Start the graph data server
(`fastnode-go/lang/python/cmds/graph-data-server`) on the same computer as
the one doing the training, or set the `SERVER` env var to an endpoint
on which the graph server is already running.

 - Set up a `fastnode_ml` virtualenv using the instructions in
 `fastnode-python/fastnode_ml/README.md` and activate it.

- Run `make` to train and validate the model.

- Run `make upload` to upload the model to S3. Afterwards, the model
can updated in Fastnode by updating the model directory in
`fastnode-go/lang/python/pythonmodels/models.go` and re-running datadeps
(`./scripts/build_datadeps.sh`).

- If you want to continue training a pre-trained model for more steps, 
run `make continue` where `STEPS` is the number of extra steps.
The summaries will be written to tensorboard named `$(MODEL_NAME)_continue`.
When viewing the summaries, simply turn on both `$(MODEL_NAME)`
and `$(MODEL_NAME)_continue`, then the two curves will both show up 
and they will look connected.

### Description of stages

These happen when `make` is run.

- `traindata`: Builds distributions of symbols on which to train.

- `train`: Trains the model, pulling training samples from the graph
data server on demand.

- `validate_attribute`: This validates attribute completions in the
newly generated model. Additionally, it runs the model on a set of
curated examples (output in `./out/curated-examples/attr.json`) and
un-curated examples generated by the pipeline (output in
`./tmp/uncurated-examples/attr`). These examples can be viewed via the
example viewer
(`fastnode-go/lang/python/pythoncompletions/cmds/example-viewer`).

## Distributed

In the distributed environment, multiple instances run the graph data
server and independently generate training samples, which are then synced
to a single GPU instance which executes the Tensorflow training logic.

- On a Linux host, set up the `fastnode_ml` virtualenv and run
`make datagen_parallel` to build the graph data server and deploy it to
the data-generation instances.

- On the GPU instance that does the training, run `make sync` in the
background to sync files from the data-generation instances.

- On the GPU instance that does the training, set up the `fastnode_ml`
virtualenv and run `SYNC_DATA=1 make train` to train the model using
synced data.

- Afterwards, run `make` to run the downstream validation logic and
`make upload` to upload the model.
